import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.signal import periodogram
from .SelfAttention_Family import SparseVariationalAttention, AttentionPool
from .TSF_TSM_layers import *

# nflows ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from nflows.flows.base import Flow
from nflows.distributions.normal import StandardNormal
from nflows.transforms.base import CompositeTransform
from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform
from nflows.transforms.coupling import PiecewiseRationalQuadraticCouplingTransform
from nflows.transforms.permutations import RandomPermutation
from nflows.transforms.normalization import BatchNorm
from nflows.nn.nets import ResidualNet

import logging

class PredictionHead(nn.Module):
    """
    ì¸ì½”ë”ê°€ ë§Œë“  ìš”ì•½ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë°›ì•„, 
    ë¯¸ë˜ ì˜ˆì¸¡ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ ì„ í˜• í—¤ë“œ.
    """
    def __init__(self, configs):
        super().__init__()
        self.pred_len = configs.pred_len
        self.enc_in = configs.enc_in
        self.head = nn.Linear(configs.d_model, configs.pred_len * configs.enc_in)

    def forward(self, summary_context):
        # summary_context shape: [B, d_model]
        output_flat = self.head(summary_context)
        # output shape: [B, pred_len, c_in]
        return output_flat.view(-1, self.pred_len, self.enc_in)

class ChunkedAutoregressiveFlowHead(nn.Module):
    def __init__(self, step_dim, context_dim, pred_len, chunk_size,
                 flow_layers=5, hidden_features=256, num_bins=16):
        super().__init__()
        self.step_dim = step_dim
        self.pred_len = pred_len
        self.chunk_size = chunk_size
        self.num_chunks = (pred_len + chunk_size - 1) // chunk_size

        self.flows = nn.ModuleList([
            create_conditional_nsf_flow(
                feature_dim=step_dim * chunk_size,
                context_dim=context_dim + step_dim * chunk_size * i,
                num_layers=flow_layers, hidden_features=hidden_features, num_bins=num_bins
            ) for i in range(self.num_chunks)
        ])

    def log_prob(self, inputs, context):
        # inputsì˜ ê¸°ëŒ€ shape: (B, pred_len, step_dim)
        B = inputs.size(0)
        
        log_probs, prev_chunks_list = [], []
        for i, flow in enumerate(self.flows):
            flat_prev_chunks = torch.cat(prev_chunks_list, dim=-1) if prev_chunks_list else context.new_empty(B, 0)
            ar_context = torch.cat([context, flat_prev_chunks], dim=-1)
            
            start, end = i * self.chunk_size, min((i + 1) * self.chunk_size, self.pred_len)
            
            # âœ… ìŠ¬ë¼ì´ì‹± í›„ view/reshape ì „ì— .contiguous()ë¥¼ ì¶”ê°€í•˜ì—¬ ë©”ëª¨ë¦¬ ê´€ë ¨ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
            chunk_target = inputs[:, start:end, :].contiguous().view(B, -1)
            
            # ë§ˆì§€ë§‰ ì²­í¬ê°€ ì‘ì„ ê²½ìš°, í¬ê¸°ë¥¼ ë§ì¶°ì£¼ê¸° ìœ„í•œ íŒ¨ë”© ì²˜ë¦¬
            if chunk_target.shape[1] < self.chunk_size * self.step_dim:
                padding = torch.zeros(B, self.chunk_size * self.step_dim - chunk_target.shape[1], device=inputs.device)
                chunk_target = torch.cat([chunk_target, padding], dim=1)

            log_probs.append(flow.log_prob(chunk_target, context=ar_context))
            
            # prev_chunks_listì— ì¶”ê°€í•  ë•Œë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
            prev_chunks_list.append(chunk_target) # ì´ë¯¸ reshape ë° paddingëœ chunk_targetì„ ì‚¬ìš©

        return torch.stack(log_probs, dim=1).sum(dim=1)

    def sample(self, num_samples, context):
        B = context.size(0)
        all_samples, prev_chunks_list = [], []
        expanded_context = context.unsqueeze(0).expand(num_samples, B, -1).reshape(num_samples * B, -1)

        for i, flow in enumerate(self.flows):
            flat_prev_chunks = torch.cat(prev_chunks_list, dim=-1) if prev_chunks_list else expanded_context.new_empty(num_samples*B, 0)
            ar_context = torch.cat([expanded_context, flat_prev_chunks], dim=-1)
            
            # nflowsì˜ sample ë©”ì„œë“œëŠ” contiguous ê´€ë ¨ ë¬¸ì œê°€ ê±°ì˜ ì—†ì§€ë§Œ, ì¼ê´€ì„±ì„ ìœ„í•´ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
            chunk_sample_flat = flow.sample(1, context=ar_context).squeeze(1)
            all_samples.append(chunk_sample_flat)
            prev_chunks_list.append(chunk_sample_flat)

        samples_padded = torch.cat(all_samples, dim=-1)
        # íŒ¨ë”©ëœ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì›ë˜ ê¸¸ì´ì— ë§ê²Œ ìë¦…ë‹ˆë‹¤.
        samples = samples_padded[:, :self.pred_len * self.step_dim]
        # ìµœì¢…ì ìœ¼ë¡œ (num_samples, B, pred_len, step_dim) í˜•íƒœë¡œ ë³µì›í•©ë‹ˆë‹¤.
        return samples.view(num_samples, B, self.pred_len, self.step_dim)

class ProbabilisticResidualModel(nn.Module):
    def __init__(self, configs):
        super().__init__()
        self.c_in = configs.enc_in
        self.pred_len = configs.pred_len
        context_dim = configs.d_model
        
        self.window_size = configs.moving_avg
        self.stride = configs.stride

        feature_dim = self.c_in * self.window_size
        
        self.flow_head = create_conditional_nsf_flow(
            feature_dim=feature_dim, 
            context_dim=context_dim,
            num_layers=configs.flow_layers, 
            hidden_features=configs.hidden_features, 
            num_bins=configs.num_bins
        )

    def forward(self, summary_context, y):
        # y shape: [B, pred_len, c_in]
        B, L, C = y.shape
        
        # --- ğŸ’¡ [í•µì‹¬] for ë£¨í”„ë¥¼ unfold ì—°ì‚°ìœ¼ë¡œ ëŒ€ì²´ ---
        # 1. yë¥¼ [B, C, L] í˜•íƒœë¡œ ë³€í™˜
        y_transposed = y.permute(0, 2, 1)
        
        # 2. unfoldë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ìœˆë„ìš°ë¥¼ í•œ ë²ˆì— ì¶”ì¶œ
        # ê²°ê³¼ shape: [B, C, num_windows, window_size]
        y_windows = y_transposed.unfold(dimension=2, size=self.window_size, step=self.stride)
        
        # 3. Flowì— ì…ë ¥í•˜ê¸° ìœ„í•´ shape ì¬ì •ë ¬ ë° flatten
        # [B, C, num_windows, window_size] -> [B, num_windows, C, window_size]
        y_windows = y_windows.permute(0, 2, 1, 3)
        num_windows = y_windows.shape[1]
        
        # [B, num_windows, C, window_size] -> [B * num_windows, C * window_size]
        y_windows_flat = y_windows.reshape(B * num_windows, -1)
        
        # 4. summary_contextë¥¼ ê° ìœˆë„ìš°ì— ë§ê²Œ í™•ì¥
        # [B, d_model] -> [B, num_windows, d_model] -> [B * num_windows, d_model]
        expanded_context = summary_context.unsqueeze(1).expand(-1, num_windows, -1)
        expanded_context = expanded_context.reshape(B * num_windows, -1)
        
        # 5. ëª¨ë“  ìœˆë„ìš°ì— ëŒ€í•´ Flowë¥¼ ë³‘ë ¬ë¡œ í•œ ë²ˆì— ì‹¤í–‰
        log_prob_windows = self.flow_head.log_prob(y_windows_flat, context=expanded_context)
        
        # 6. ì „ì²´ í‰ê·  Loss ê³„ì‚°
        total_log_prob = log_prob_windows.mean()
        
        return total_log_prob

    def sample(self, summary_context, num_samples=1):
        self.eval()
        with torch.no_grad():
            B = summary_context.size(0)
            num_windows = (self.pred_len - self.window_size) // self.stride + 1
            
            # 1. ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª¨ë“  ìœˆë„ìš°ì— ë§ê²Œ í™•ì¥
            expanded_context = summary_context.unsqueeze(1).expand(-1, num_windows, -1)
            expanded_context = expanded_context.reshape(B * num_windows, -1)
            
            # 2. ëª¨ë“  ìœˆë„ìš°ì— ëŒ€í•œ ìƒ˜í”Œì„ ë³‘ë ¬ë¡œ í•œ ë²ˆì— ìƒì„±
            # sample_windows_flat shape: [num_samples, B * num_windows, window_size * c_in]
            sample_windows_flat = self.flow_head.sample(num_samples, context=expanded_context)
            
            # 3. ìœˆë„ìš° shapeìœ¼ë¡œ ë³µì›
            # [num_samples, B, num_windows, window_size, c_in]
            sample_windows = sample_windows_flat.view(num_samples, B, num_windows, self.window_size, self.c_in)
            
            # 4. ê²¹ì¹˜ëŠ”(Overlapping) ìœˆë„ìš°ë“¤ì„ í‰ê· ë‚´ì–´ ìµœì¢… ì‹œí€€ìŠ¤ ìƒì„± (Overlap-add ë°©ì‹)
            final_samples = torch.zeros(num_samples, B, self.pred_len, self.c_in, device=summary_context.device)
            counts = torch.zeros(B, self.pred_len, self.c_in, device=summary_context.device)
            
            for i in range(num_windows):
                start_idx = i * self.stride
                end_idx = start_idx + self.window_size
                final_samples[:, :, start_idx:end_idx, :] += sample_windows[:, :, i, :, :]
                counts[:, start_idx:end_idx, :] += 1
            
            final_samples = final_samples / counts.unsqueeze(0)

        return final_samples

class Decoder(nn.Module):
    def __init__(self, configs):
        super().__init__()
        
        # ë””ì½”ë”ì˜ ì…ë ¥(íƒ€ê²Ÿ ì‹œí€€ìŠ¤)ì„ d_model ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì„ë² ë”© ë ˆì´ì–´
        self.embedding = nn.Linear(configs.enc_in, configs.d_model)
        
        # DecoderLayerë¥¼ num_layers ë§Œí¼ ìŒ“ìŒ
        self.layers = nn.ModuleList([
            DecoderLayer(configs.d_model, configs.n_heads, configs.d_ff, configs.dropout) for _ in range(configs.num_layers)
        ])
        
        # ìµœì¢… ì¶œë ¥ì„ ì›ë˜ í”¼ì²˜ ì°¨ì›(c_in)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œì ì…˜ ë ˆì´ì–´
        self.projection = nn.Linear(configs.d_model, configs.enc_in)

    def forward(self, x, memory):
        # x: ë””ì½”ë”ì˜ ì…ë ¥. shape: [Batch, Target_Seq_Len, c_in]
        # memory: ì¸ì½”ë”ì˜ ì „ì²´ ì¶œë ¥. shape: [Batch, Source_Seq_Len, d_model]
        
        # 1. ì…ë ¥ ì„ë² ë”©
        x = self.embedding(x)
        
        # 2. Self-Attentionì„ ìœ„í•œ Look-ahead ë§ˆìŠ¤í¬ ìƒì„±
        #    ë””ì½”ë”ê°€ ì˜ˆì¸¡ ì‹œì  tì—ì„œ, të³´ë‹¤ ë¯¸ë˜ì˜ ì •ë³´ë¥¼ ë³´ì§€ ëª»í•˜ê²Œ í•¨
        seq_len = x.size(1)
        tgt_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device) * float('-inf'), diagonal=1)

        # 3. ëª¨ë“  ë””ì½”ë” ë ˆì´ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í†µê³¼
        for layer in self.layers:
            x = layer(x, memory, tgt_mask=tgt_mask)
            
        # 4. ìµœì¢… ì¶œë ¥
        return self.projection(x)